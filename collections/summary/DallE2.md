---
layout: summary
---

# DALL-E 2

*This summary is summarizing and explaining DALL-E 2 [(https://arxiv.org/abs/2204.06125)](https://arxiv.org/abs/2204.06125) paper in Thai.* Underconstruction

## สรุปแบบย่อ

DALL-E 2 เป็น Encoder-Decoder Model ที่แบ่งออกเป็นสองส่วน ส่วนแรกเป็น Encoder ใช้ CLIP เพื่อแปลงข้อความให้เป็นภาพผ่านการ encode ข้อความให้เป็น embedding แล้วแปลงให้เป็น embedding ภาพเพื่อสร้าง prior distribution ในการสร้างภาพ และส่วนที่สองคือ Decoder ทำการสร้างภาพจาก embedding บน prior distribution

<img width="916" alt="fig2" src="https://user-images.githubusercontent.com/50354662/212390595-3cdae2aa-9601-4927-9697-bd945f7b8754.png">

ข้อดีของการทำอย่างนี้ก็คือเราสามารถสร้างภาพที่มีความแตกต่างกันได้จากข้อความอันเดียว รวมไปถึงสามารถทำ Zero-shot Learning เพื่อสร้างภาพที่ไม่เคยมีอยู่มาก่อนจากข้อความที่ไม่เคยเห็นมาก่อนได้

## บทนำ

เนื่องด้วยช่วงนี้งานวิจัยทางด้าน Computer Vision 

## อะไรคือ Diffusion Model

## นอกเรื่องไป Meta Learning

### บทนำสู่ Meta Learning: Distance-based Learning
สมมติผมอยากสอน Neural network ให้จำแนกระหว่างเลขที่เขียนด้วยมือสองตัว 0 กับเลข 1 เช่น (1,0) หรือ (0,0) ว่าเลขทั้งสองตัวเป็นเลขเดียวกันไหม ตามปกติเราก็สามารถสร้าง Neural networks ที่จำแนกว่าเลขแรกเป็นเลขอะไร และเลขที่สองเป็นเลขอะไรแล้วมาเทียบกัน กล่าวคือเราทำการ Train NN บน cross-entropy loss (จากการที่ Response/output ของเราเป็น Binary output เหมือนใน Bernoulli process)

แต่เราจะทำอย่างนั้นทำไมในเมื่อเราสามารถ "สอนให้ NN เรียนรู้" การแยกความแตกต่างได้ อ่ะ เราลองทำแบบแรกก่อนแล้วดูว่า NN มันมองตัวเลขเป็นอย่างไง

{% include_relative latent.html max-width="600px" %}

ตาม t-SNE plot ของเวกเตอร์ใน layer สุดท้ายของ NN แบบปกติของเรา เลข 0 จะแทนด้วยสีแดงและเลข 1 จะแทนด้วยสีฟ้า จะเห็นว่าเลขกลุ่มเดียวกันจะอยู่ใกล้กันบน latent space! ทำให้เราสามารถนิยาม euclidean metric หรืออาจจะเป็น cosine similarity, inner product, etc. เพื่อเทียบว่าตัวเลขดังกล่าวเป็นเลขเดียวกันหรือไม่

### แล้วจะทำอย่างนี้ไปเพื่ออะไร

![dang](https://user-images.githubusercontent.com/50354662/212450227-2914514f-beb2-4041-a7be-91faa2cc9858.jpg)


สมมติว่าเรามีตัวเลขทั้งหมด 10 ตัว หรือถ้าเรามีภาพชิ้นเนื้อแล้วเราอยากรู้ว่าคนนั้นบาดเจ็บอย่างไง แน่นอนการสร้าง Model ที่จำแนกทุกอย่างได้ดีกว่า แต่เราก็สามารถใช้วิธีง่ายๆ นี้ในการทำให้ชีวิตของเราง่ายขึ้นได้

### แล้วเกี่ยวอะไรกับงานนี้

Spoiler Alert: Zero-shot learning ใช้แนวคิดคล้ายๆ กันกับตัวอย่างก่อนหน้าที่เราอธิบายไป

คือจากตัวอย่างก่อนหน้า สมมติเราใช้ Cosine similarity จะเห็นว่าเราสามารถนำ Embedding มาเทียบเพื่อหาว่าภาพแรกต่างจากภาพสองหรือไม่ แต่เราไม่จำเป็นต้องหาความแตกต่างอย่างเดียว แต่เราสามารถใช้การที่เราสามารถเทียบค่าเหล่านั้นได้เพื่อเป็นการเข้าใจในข้อความ และเข้าใจตัวรูปภาพได้ มาดูตัวอย่างต่อไปกัน

![manifold](https://user-images.githubusercontent.com/50354662/212417602-5cc0e99a-2c41-40c0-84ae-dd175d872943.svg)

ภาพนี้สร้างจาก Decoder ที่รับ input เป็นเวกเตอร์สองมิติ (ค่าแสดงโดยแกนมิติต่างๆ) ของ Variational Autoencoder (VAE model คล้ายๆ กับ DALL-E 2) ที่ถูกสอนด้วย MNIST data จะเห็นว่าการที่เราเคลื่อนที่ไปตามแกนต่างๆ ก็จะส่งผลให้ภาพที่สร้างขึ้นต่างกัน แต่สิ่งหนึ่งที่น่าสนใจจากตรงนี้คือ ตัว NN ไม่จำเป็นต้องเคยเห็นค่าเหล่านั้นมาก่อน ก็สามารถสร้างภาพเหล่านั้นได้ และคล้ายกับตัวอย่างก่อนหน้า ค่าที่ใกล้ๆ กัน (ในแต่ละมิติ) ก็จะให้ภาพที่ีคล้ายคลึงกัน

## แล้ว CLIP คืออะไร

## แล้วมันเกี่ยวอะไรกับ Paper นี้
